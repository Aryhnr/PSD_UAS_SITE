[
  {
    "objectID": "PSDtugasdata2.html",
    "href": "PSDtugasdata2.html",
    "title": "BUSSNIS UNDERSTANDING",
    "section": "",
    "text": "Data ini ditujukan untuk analisis dan klasifikasi pasien berdasarkan atribut yang diberikan, terutama untuk mengidentifikasi pasien yang adalah donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis.\nBerikut Untuk menentukan Klasifikasi pasien termasuk donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis :\n\nUsia (dalam tahun)\nJenis Kelamin (f,m)\nALB\nALP\nALT\nAST\nBIL\nCHE\nCHOL\nCREA\nGGT\nPROT"
  },
  {
    "objectID": "PSDtugasdata2.html#tujuan-proyek",
    "href": "PSDtugasdata2.html#tujuan-proyek",
    "title": "BUSSNIS UNDERSTANDING",
    "section": "",
    "text": "Data ini ditujukan untuk analisis dan klasifikasi pasien berdasarkan atribut yang diberikan, terutama untuk mengidentifikasi pasien yang adalah donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis.\nBerikut Untuk menentukan Klasifikasi pasien termasuk donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis :\n\nUsia (dalam tahun)\nJenis Kelamin (f,m)\nALB\nALP\nALT\nAST\nBIL\nCHE\nCHOL\nCREA\nGGT\nPROT"
  },
  {
    "objectID": "PSDtugasdata2.html#deskripsi-data",
    "href": "PSDtugasdata2.html#deskripsi-data",
    "title": "BUSSNIS UNDERSTANDING",
    "section": "DESKRIPSI DATA",
    "text": "DESKRIPSI DATA\nData ini dikumpulkan untuk tujuan menentukan klasifikasi pasien berdasarkan parameter kesehatan dan demografis. Setiap baris mewakili satu pasien, dengan informasi yang mencakup usia, jenis kelamin, dan sejumlah parameter kesehatan seperti ALB, ALP, ALT, AST, BIL, CHE, CHOL, CREA, GGT, dan PROT. Tujuan utama adalah mengklasifikasikan pasien ke dalam kategori diagnostik tertentu, seperti donor darah, tersangka donor darah, penderita Hepatitis, Fibrosis, atau Sirosis.\nData menyajikan keberagaman pasien dalam aspek usia dan jenis kelamin, memberikan konteks demografis. Selain itu, variabel-variabel kesehatan seperti kadar enzim, protein, dan zat lain dalam darah memberikan informasi tentang kondisi kesehatan dan fungsi organ pasien, terutama hati.\nAnalisis lebih lanjut dari data ini dapat melibatkan eksplorasi tren, identifikasi pola, dan pengembangan model prediktif untuk memahami hubungan antara parameter kesehatan dengan klasifikasi pasien. Informasi ini dapat bermanfaat untuk pengambilan keputusan klinis dan perencanaan perawatan yang lebih efektif berdasarkan karakteristik individu pasien.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(\"ignore\")\nfrom sklearn.model_selection import GridSearchCV\nfrom imblearn.over_sampling import SMOTE\nfrom pickle import dump\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.feature_selection import SelectKBest, mutual_info_classif\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n\n\ncsv=\"/content/drive/MyDrive/PSD/Tugas data baru/HepatitisCdata.csv\"\ndata = pd.read_csv(csv)\ndata\n\n\n  \n    \n\n\n\n\n\n\nCategory\nAge\nSex\nALB\nALP\nALT\nAST\nBIL\nCHE\nCHOL\nCREA\nGGT\nPROT\n\n\n\n\n0\n0=Blood Donor\n32\nm\n38.5\n52.5\n7.7\n22.1\n7.5\n6.93\n3.23\n106.0\n12.1\n69.0\n\n\n1\n0=Blood Donor\n32\nm\n38.5\n70.3\n18.0\n24.7\n3.9\n11.17\n4.80\n74.0\n15.6\n76.5\n\n\n2\n0=Blood Donor\n32\nm\n46.9\n74.7\n36.2\n52.6\n6.1\n8.84\n5.20\n86.0\n33.2\n79.3\n\n\n3\n0=Blood Donor\n32\nm\n43.2\n52.0\n30.6\n22.6\n18.9\n7.33\n4.74\n80.0\n33.8\n75.7\n\n\n4\n0=Blood Donor\n32\nm\n39.2\n74.1\n32.6\n24.8\n9.6\n9.15\n4.32\n76.0\n29.9\n68.7\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n610\n3=Cirrhosis\n62\nf\n32.0\n416.6\n5.9\n110.3\n50.0\n5.57\n6.30\n55.7\n650.9\n68.5\n\n\n611\n3=Cirrhosis\n64\nf\n24.0\n102.8\n2.9\n44.4\n20.0\n1.54\n3.02\n63.0\n35.9\n71.3\n\n\n612\n3=Cirrhosis\n64\nf\n29.0\n87.3\n3.5\n99.0\n48.0\n1.66\n3.63\n66.7\n64.2\n82.0\n\n\n613\n3=Cirrhosis\n46\nf\n33.0\nNaN\n39.0\n62.0\n20.0\n3.56\n4.20\n52.0\n50.0\n71.0\n\n\n614\n3=Cirrhosis\n59\nf\n36.0\nNaN\n100.0\n80.0\n12.0\n9.07\n5.30\n67.0\n34.0\n68.0\n\n\n\n\n\n615 rows × 13 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nJUMLAH DATA\nJumlah data mengacu pada total entitas atau elemen dalam suatu kumpulan atau struktur data. Ini bisa berupa jumlah baris dalam sebuah tabel, elemen dalam sebuah list, karakter dalam sebuah string, atau item dalam struktur data lainnya. Pemahaman jumlah data menjadi penting ketika kita ingin mengukur ukuran atau omvang dari setiap koleksi data dan memberikan gambaran tentang seberapa besar atau kecil kumpulan data tersebut. dari data yang dipakai pada proyek ini memiliki jumlah data 615 rows dengan 13 kolom, dari data tersebut dapat diketahui juga data di setiap category :\n\nBlood Donor : 533 data\nSuspect Blood Donor : 7 data\nHepatitis : 24 data\nFibrosis : 21 data\nCirrhosis : 30 data\n\n\ndata.shape\n\n(615, 13)\n\n\n\nimport matplotlib.pyplot as plt\n\n# Menghitung Jumlah data setiap Category\ncounts = [\n    data[data['Category'] == '0=Blood Donor']['Age'].count(),\n    data[data['Category'] == '0s=suspect Blood Donor']['Age'].count(),\n    data[data['Category'] == '1=Hepatitis']['Age'].count(),\n    data[data['Category'] == '2=Fibrosis']['Age'].count(),\n    data[data['Category'] == '3=Cirrhosis']['Age'].count()\n]\n\n# Define the categories\ncategories = ['Blood Donor', 'Suspect Blood Donor', 'Hepatitis', 'Fibrosis', 'Cirrhosis']\n\n# Create a bar chart\nplt.bar(categories, counts)\nplt.xlabel('Category')\nplt.ylabel('Count')\nplt.title('Jumlah data setiap Category')\nfor i, count in enumerate(counts):\n    plt.text(categories[i], count, str(count), ha='center', va='bottom')\nplt.show()\n\n\n\n\n\n\nTYPE DATA\nSemua atribut bertype data numerik kecuali atribut pada kolom “Category” dan “Sex”\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 615 entries, 0 to 614\nData columns (total 13 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Category  615 non-null    object \n 1   Age       615 non-null    int64  \n 2   Sex       615 non-null    object \n 3   ALB       614 non-null    float64\n 4   ALP       597 non-null    float64\n 5   ALT       614 non-null    float64\n 6   AST       615 non-null    float64\n 7   BIL       615 non-null    float64\n 8   CHE       615 non-null    float64\n 9   CHOL      605 non-null    float64\n 10  CREA      615 non-null    float64\n 11  GGT       615 non-null    float64\n 12  PROT      614 non-null    float64\ndtypes: float64(10), int64(1), object(2)\nmemory usage: 62.6+ KB\n\n\n\n\nMapping numeric values\n“Mapping numeric values” merujuk pada proses mengaitkan atau menghubungkan suatu nilai numerik dengan nilai lainnya. Hal ini dapat dilakukan untuk berbagai tujuan, seperti mengubah rentang nilai, mengkategorikan data, atau menciptakan representasi yang lebih mudah dimengerti.\nBerikut adalah beberapa contoh penggunaan “mapping numeric values”:\nNormalisasi Data: Dalam analisis data, seringkali penting untuk mengubah nilai-nilai numerik sehingga mereka berada dalam rentang tertentu. Misalnya, jika Anda memiliki data yang tersebar di antara 0 dan 100, Anda mungkin ingin mengubahnya menjadi rentang 0 hingga 1.\nKategorisasi: Anda dapat menggolongkan nilai numerik ke dalam kategori tertentu. Misalnya, jika Anda memiliki data usia, Anda bisa membuat kategori seperti “anak-anak,” “remaja,” dan “dewasa” dengan mengaitkan rentang usia tertentu dengan setiap kategori.\nEncoding: Dalam machine learning, khususnya pada pembelajaran mesin terhadap kategori atau label, seringkali diperlukan untuk mengonversi label kategori menjadi representasi numerik. Ini bisa dilakukan dengan membuat peta antara setiap kategori dan nilai numerik tertentu.\nVisualisasi Data: Dalam visualisasi data, Anda mungkin ingin mengaitkan nilai-nilai numerik dengan warna atau ukuran untuk memperjelas pola atau perbedaan dalam data.\nTransformasi Fungsi: Pemetaan nilai numerik dapat dilakukan melalui fungsi matematis atau transformasi. Sebagai contoh, mengkuadratkan atau mengakarkan nilai-nilai numerik untuk mengubah distribusi data.\nPada proses ini ada 2 kolom yang akan di mapping diantaranya ada “Category” pada kolom ini adalah kolom target yang aakan di mapping yang dimana value sebelumnya ada beberapa kategeri tapi pada dasarnya ada dua kategori yaitu donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis, jadi disini mapping menjadi dua yang dimana yang donor darah = 0 dan hepatitis C dengan tahap perkembangannya = 1. Kemudian kolom “Sex” pada kolom ini yang akan di mapping m/male = 1 dan f/famale = 2\n\ndata.Category.unique()\n\narray(['0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis',\n       '2=Fibrosis', '3=Cirrhosis'], dtype=object)\n\n\n\ndata['Category'] = data['Category'].map({'0=Blood Donor': 0, '0s=suspect Blood Donor': 0,\n                                     \"1=Hepatitis\" : 1, \"2=Fibrosis\" : 1, \"3=Cirrhosis\" : 1})\n\ndata['Sex'] = data['Sex'].map({'m': 1, 'f': 2})\n\n\ndata.head()\n\n\n  \n    \n\n\n\n\n\n\nCategory\nAge\nSex\nALB\nALP\nALT\nAST\nBIL\nCHE\nCHOL\nCREA\nGGT\nPROT\n\n\n\n\n0\n0\n32\n1\n38.5\n52.5\n7.7\n22.1\n7.5\n6.93\n3.23\n106.0\n12.1\n69.0\n\n\n1\n0\n32\n1\n38.5\n70.3\n18.0\n24.7\n3.9\n11.17\n4.80\n74.0\n15.6\n76.5\n\n\n2\n0\n32\n1\n46.9\n74.7\n36.2\n52.6\n6.1\n8.84\n5.20\n86.0\n33.2\n79.3\n\n\n3\n0\n32\n1\n43.2\n52.0\n30.6\n22.6\n18.9\n7.33\n4.74\n80.0\n33.8\n75.7\n\n\n4\n0\n32\n1\n39.2\n74.1\n32.6\n24.8\n9.6\n9.15\n4.32\n76.0\n29.9\n68.7\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nMemeriksa kembali tipe data setelah transformasi\n\ndata.dtypes\n\nCategory      int64\nAge           int64\nSex           int64\nALB         float64\nALP         float64\nALT         float64\nAST         float64\nBIL         float64\nCHE         float64\nCHOL        float64\nCREA        float64\nGGT         float64\nPROT        float64\ndtype: object"
  },
  {
    "objectID": "PSDtugasdata2.html#eksplorasi-data",
    "href": "PSDtugasdata2.html#eksplorasi-data",
    "title": "BUSSNIS UNDERSTANDING",
    "section": "EKSPLORASI DATA",
    "text": "EKSPLORASI DATA\nEksplorasi Data (ED) adalah suatu proses analisis awal pada data untuk memahami dan meringkas karakteristik utama dari data tersebut. Tujuan dari eksplorasi data adalah mengidentifikasi pola, tren, anomali, dan informasi penting lainnya tanpa membuat asumsi sebelumnya. Eksplorasi data merupakan tahap kritis dalam analisis data dan dapat melibatkan berbagai metode, teknik, dan visualisasi data.\n\nDescribe data\nmengembalikan DataFrame baru yang berisi berbagai statistik untuk setiap kolom dalam DataFrame asli data. Statistik tersebut umumnya mencakup:\n\nCount: Jumlah nilai non-null.\nMean: Nilai rata-rata atau rata-rata.\nStd: Deviasi standar, ukuran sebaran data.\nMin: Nilai minimum.\n25%: Kuartil pertama atau persentil ke-25.\n50%: Mediana atau persentil ke-50.\n75%: Kuartil ketiga atau persentil ke-75.\nMax: Nilai maksimum.\n\nStatistik ini memberikan ringkasan cepat tentang distribusi setiap kolom numerik dalam DataFrame, membantu analis dan ilmuwan data untuk mendapatkan gambaran tentang kecenderungan sentral data, sebaran, dan bentuk keseluruhan. Perlu diingat bahwa statistik yang tepat dapat bervariasi berdasarkan versi pandas atau konfigurasi tertentu yang digunakan.\n\ndata.describe()\n\n\n  \n    \n\n\n\n\n\n\nCategory\nAge\nSex\nALB\nALP\nALT\nAST\nBIL\nCHE\nCHOL\nCREA\nGGT\nPROT\n\n\n\n\ncount\n615.000000\n615.000000\n615.000000\n614.000000\n597.000000\n614.000000\n615.000000\n615.000000\n615.000000\n605.000000\n615.000000\n615.000000\n614.000000\n\n\nmean\n0.121951\n47.408130\n1.386992\n41.620195\n68.283920\n28.450814\n34.786341\n11.396748\n8.196634\n5.368099\n81.287805\n39.533171\n72.044137\n\n\nstd\n0.327496\n10.055105\n0.487458\n5.780629\n26.028315\n25.469689\n33.090690\n19.673150\n2.205657\n1.132728\n49.756166\n54.661071\n5.402636\n\n\nmin\n0.000000\n19.000000\n1.000000\n14.900000\n11.300000\n0.900000\n10.600000\n0.800000\n1.420000\n1.430000\n8.000000\n4.500000\n44.800000\n\n\n25%\n0.000000\n39.000000\n1.000000\n38.800000\n52.500000\n16.400000\n21.600000\n5.300000\n6.935000\n4.610000\n67.000000\n15.700000\n69.300000\n\n\n50%\n0.000000\n47.000000\n1.000000\n41.950000\n66.200000\n23.000000\n25.900000\n7.300000\n8.260000\n5.300000\n77.000000\n23.300000\n72.200000\n\n\n75%\n0.000000\n54.000000\n2.000000\n45.200000\n80.100000\n33.075000\n32.900000\n11.200000\n9.590000\n6.060000\n88.000000\n40.200000\n75.400000\n\n\nmax\n1.000000\n77.000000\n2.000000\n82.200000\n416.600000\n325.300000\n324.000000\n254.000000\n16.410000\n9.670000\n1079.100000\n650.900000\n90.000000\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\nMatrix correlation\n“Having a look at the correlation matrix” adalah istilah yang merujuk pada kegiatan memeriksa atau menganalisis matriks korelasi. Matriks korelasi adalah suatu tabel yang menunjukkan seberapa erat hubungan antara dua atau lebih variabel. Ini memberikan informasi tentang arah dan kekuatan hubungan antar variabel tersebut.\nMatriks korelasi umumnya digunakan dalam statistika, analisis data, dan machine learning untuk memahami sejauh mana variabel-variabel saling terkait. Nilai korelasi berkisar antara -1 hingga 1, dengan interpretasi sebagai berikut:\n\n1: Korelasi sempurna (positif)\n0: Tidak ada korelasi\n-1: Korelasi sempurna (negatif)\n\n\nfig, ax = plt.subplots(figsize=(10,8))\nsns.heatmap(data.corr(), annot=True, cbar=True, cmap='coolwarm')\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\nSimple EDA\nSimple EDA (Exploratory Data Analysis) adalah pendekatan awal dalam menganalisis dataset untuk mendapatkan pemahaman awal tentang karakteristik data dan mengidentifikasi pola atau informasi yang menarik. EDA merupakan langkah kritis dalam tahap persiapan data sebelum melakukan analisis yang lebih lanjut. Tujuannya adalah untuk membantu peneliti atau analis data memahami struktur dataset, mengidentifikasi anomali, dan merumuskan pertanyaan atau hipotesis yang lebih mendalam. melakukan Exploratory Data Analysis (EDA) dengan membuat histogram untuk masing-masing variabel numerik dalam dataset, memperhatikan distribusi data dan melihat perbedaan distribusi antar kategori (‘Category’).\n\nfig, axes = plt.subplots(6, 2, figsize=(12, 15))\naxes = axes.flatten()\n\ncolumns = ['Sex','Age','ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT']\n\nfor i, column in enumerate(columns):\n    sns.histplot(x=data[column], hue=data['Category'], kde=True, ax=axes[i])\n    axes[i].set_title(f'Histogram of {column}')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\nDESKRIPSI SETIAP FEATURE DAN CARA PENGAMBILAN\nPenjelasan dari setiap Featur data, Atribut 1 sampai dengan 4 mengacu pada data pasien:\n\nKategori (diagnosis): Merupakan variabel target atau output yang ingin diprediksi atau dianalisis. Mewakili diagnosis pasien dan memiliki kategori nilai seperti ‘0=Donor Darah’, ‘0s=tersangka Donor Darah’, ‘1=Hepatitis’, ‘2=Fibrosis’, ‘3=Sirosis’. Ini adalah variabel kategorikal.\nUsia/Age (dalam tahun): Merupakan fitur yang mencatat usia pasien dalam tahun. Ini adalah variabel numerik kontinu dan dapat memberikan informasi tentang distribusi usia pasien dalam dataset.\nJenis Kelamin (f,m): Merupakan kategorisasi jenis kelamin pasien, dengan nilai ‘f’ untuk perempuan dan ‘m’ untuk laki-laki. Ini adalah variabel kategorikal biner.\nALB (Albumin): Albumin adalah protein yang diproduksi oleh hati dan merupakan salah satu komponen utama dalam serum darah. Pengukuran kadar albumin dapat memberikan informasi tentang fungsi hati.\nALP (Alkaline Phosphatase): Alkaline phosphatase adalah enzim yang ditemukan di hati dan tulang. Peningkatan ALP dalam darah dapat menunjukkan masalah hati atau gangguan tulang.\nALT (Alanine Aminotransferase): ALT adalah enzim hati yang terlibat dalam metabolisme asam amino. Peningkatan ALT dalam darah dapat menjadi tanda kerusakan hati, seperti pada hepatitis.\nAST (Aspartate Aminotransferase): AST juga merupakan enzim hati yang terlibat dalam metabolisme asam amino. Kadar AST yang tinggi dalam darah dapat mengindikasikan kerusakan hati atau gangguan lainnya.\nBIL (Bilirubin): Bilirubin adalah pigmen kuning yang dihasilkan ketika sel darah merah hancur. Kadar bilirubin yang tinggi dapat menjadi tanda masalah hati atau masalah dengan proses penguraian bilirubin dalam tubuh.\nCHE (Cholinesterase): Cholinesterase adalah enzim yang dapat memberikan informasi tentang fungsi hati. Penurunan kadar cholinesterase dalam darah dapat mengindikasikan kerusakan hati.\nCHOL (Cholesterol): Kolesterol adalah lemak yang penting untuk tubuh, tetapi kadar kolesterol yang tinggi dalam darah dapat meningkatkan risiko penyakit jantung.\nCREA (Creatinine): Creatinine adalah produk sisa dari metabolisme otot. Kadar kreatinin dalam darah dapat memberikan informasi tentang fungsi ginjal.\nGGT (Gamma-Glutamyl Transferase): GGT adalah enzim yang ditemukan di hati dan dapat meningkat pada berbagai gangguan hati, termasuk penyakit hati alkoholik.\nPROT (Protein): Kadar total protein dalam darah dapat memberikan informasi tentang status gizi dan kesehatan umum. Kadar protein yang rendah dalam darah dapat menjadi tanda masalah gizi atau penyakit hati.\n\nTeknik Pengambilan Sampel dengan menggunakan Darah (Serum atau Plasma):\n\nAlat Pengambilan Sampel: Jarum suntik atau sarung tangan pengambil darah (vacutainer).\nTeknik: Sampel darah biasanya diambil dari vena di lengan, seringkali dari vena di bagian dalam siku. Pada beberapa uji, dapat digunakan darah kapiler dari ujung jari.\nPersiapan: Pasien biasanya diminta untuk berpuasa sebelum pengambilan darah pada uji tertentu.\n\n\n\nMISSING VALUE\nMissing value (nilai yang hilang) dalam konteks data merujuk pada keadaan di mana tidak ada nilai atau informasi yang tersedia untuk suatu variabel atau kolom pada suatu pengamatan atau baris data tertentu. Missing value dapat muncul karena beberapa alasan, termasuk kesalahan pengukuran, kegagalan perangkat, atau karena karakteristik alami dari data.\nDalam analisis data, penanganan missing value menjadi penting karena dapat memengaruhi hasil analisis dan model yang dibangun. Beberapa strategi umum untuk menangani missing value termasuk:\n\nMenghapus Baris dengan Missing Value: Metode ini melibatkan penghapusan seluruh baris data yang mengandung missing value. Namun, ini dapat menyebabkan kehilangan informasi yang berharga jika banyak data hilang.\nImputasi: Imputasi melibatkan mengisi missing value dengan nilai yang diestimasi berdasarkan data yang ada. Ini bisa berupa mean, median, modus, atau nilai yang dihitung dari data lain.\nModel Berbasis Imputasi: Menggunakan model prediktif untuk memprediksi nilai yang hilang berdasarkan variabel lain. Contoh model berbasis imputasi termasuk regresi atau algoritma machine learning.\nPeningkatan Pengumpulan Data: Melibatkan upaya untuk meningkatkan pengumpulan data agar lebih lengkap dan mengurangi jumlah missing value di masa depan.\nMenandai Missing Value: Menggunakan penanda khusus (seperti NaN - Not a Number) untuk mengidentifikasi missing value dan mengizinkan model atau analisis data untuk mengatasi keberadaan nilai yang hilang secara eksplisit.\n\n\n#Mencari data missing value\ndata.isna().sum()\n\nCategory     0\nAge          0\nSex          0\nALB          1\nALP         18\nALT          1\nAST          0\nBIL          0\nCHE          0\nCHOL        10\nCREA         0\nGGT          0\nPROT         1\ndtype: int64\n\n\nPada test diatas detemukan missing value pada table : - ALB : 1 - ALP : 18 - ALT : 1 - CHOL : 10 - PROT : 1\nMengisi Missing value dengan Rata-Rata\n\n#impute missing data\n\ndata['ALB'].fillna(data['ALB'].mean(), inplace=True)\ndata['ALP'].fillna(data['ALP'].mean(), inplace=True)\ndata['ALT'].fillna(data['ALT'].mean(), inplace=True)\ndata['CHOL'].fillna(data['CHOL'].mean(), inplace=True)\ndata['PROT'].fillna(data['PROT'].mean(), inplace=True)\n\nPengecekan Kembali Missng value\n\ndata.isnull().sum()\n\nCategory    0\nAge         0\nSex         0\nALB         0\nALP         0\nALT         0\nAST         0\nBIL         0\nCHE         0\nCHOL        0\nCREA        0\nGGT         0\nPROT        0\ndtype: int64\n\n\nMissing value sudah terisi\n\n\nBalencing Data\nKumpulan data yang tidak seimbang menimbulkan tantangan umum bagi praktisi pembelajaran mesin dalam masalah klasifikasi biner. Skenario ini sering muncul dalam aplikasi bisnis praktis seperti deteksi penipuan, pemfilteran spam , penemuan penyakit langka, dan deteksi kesalahan perangkat keras. Untuk mengatasi masalah ini, salah satu teknik yang populer adalah Synthetic Minority Oversampling Technique (SMOTE). SMOTE dirancang khusus untuk mengatasi kumpulan data yang tidak seimbang dengan menghasilkan sampel sintetis untuk kelas minoritas.\n\ndata['Category'].value_counts()\n\n0    540\n1     75\nName: Category, dtype: int64\n\n\nDapat dilihat hasil dari percobaan diatas menghasilkan data yang sangat tidak seimbang 540 berbanding dengang 75, tentu hasil ini memiliki perbadaan yang sangat jauh, oleh karena itu perlu adanya balencing data.\n\n\nOutliers\nOutliers, atau nilai-nilai ekstrem, adalah titik data yang signifikan atau ekstrim yang berbeda secara signifikan dari mayoritas data dalam sebuah kumpulan data. Outliers dapat muncul dalam berbagai bentuk dan dapat mempengaruhi analisis statistik karena mereka dapat menyebabkan kesalahan dalam estimasi parameter dan menarik hasil analisis ke arah yang tidak akurat.\n\nfig, axes = plt.subplots(5, 2, figsize=(12, 15))\naxes = axes.flatten()\n\ncolumns = ['ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT']\n\nfor i, column in enumerate(columns):\n    sns.boxplot(x=data['Category'], y=data[column], ax=axes[i])\n    axes[i].set_title(f'Boxplot of {column}')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "PSDtugasdata2.html#memisahkan-feature-dan-target",
    "href": "PSDtugasdata2.html#memisahkan-feature-dan-target",
    "title": "BUSSNIS UNDERSTANDING",
    "section": "Memisahkan Feature dan Target",
    "text": "Memisahkan Feature dan Target\nPada tahap ini akan melakukan pemisahan terhadap sebuah colom, yang nantinya akan dipisah menjadi mana kolom sebagai feature dan mana kolom yang sebagai target, berikut table yang akan dipisah : - Feature : Age, Sex, ALB, ALP, ALT, AST, BIL, CHE, CHOL, CREA, GGT, PROT - Targer : Category\n\n# Memisahkan data feature dan target\nX = data.drop(\"Category\", axis=1)\ny = data['Category']"
  },
  {
    "objectID": "PSDtugasdata2.html#seleksi-feature",
    "href": "PSDtugasdata2.html#seleksi-feature",
    "title": "BUSSNIS UNDERSTANDING",
    "section": "Seleksi Feature",
    "text": "Seleksi Feature\nInformation Gain adalah ukuran yang digunakan dalam konteks pohon keputusan (decision tree) untuk menilai seberapa baik suatu fitur dapat memisahkan data menjadi kelas yang berbeda. Information Gain dihitung dengan mengukur seberapa banyak informasi yang diberikan oleh suatu fitur terhadap pemisahan kelas dalam suatu dataset. Semakin tinggi Information Gain, semakin baik fitur tersebut dalam memprediksi kelas.\nInformation Gain biasanya digunakan dalam algoritma pembelajaran mesin yang berbasis pohon, seperti ID3 (Iterative Dichotomiser 3) atau C4.5. Pada setiap tahap pembangunan pohon keputusan, algoritma mencari fitur dengan Information Gain tertinggi untuk memilih sebagai node pemisah berikutnya.\nk-Best: k-Best merujuk pada teknik pemilihan fitur di mana kita memilih k fitur terbaik berdasarkan suatu metrik atau skor tertentu. Metode ini membantu untuk mengurangi dimensi dataset dengan memilih subset fitur yang paling informatif atau yang paling berkontribusi dalam memprediksi variabel target.\nTeknik pemilihan fitur k-Best umumnya menggunakan skor atau metrik seperti chi-square, f-regression, mutual information, dll., untuk menilai pentingnya setiap fitur. Kemudian, k fitur terbaik dipilih berdasarkan skor tersebut.\n\n# Mencari fitur data terbaik menggunakan information gain\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import mutual_info_classif\n\n# Menghitung Information Gain untuk setiap fitur\ninformation_gains = mutual_info_classif(X, y, discrete_features=[0])  # Indeks 0 mengacu pada kolom 'Sex' yang merupakan variabel kategorikal\n\n# Membuat DataFrame dengan nama fitur dan nilai Information Gain\nfeature_importance = pd.DataFrame({'Feature': X.columns, 'Information Gain': information_gains})\n\n# Mengurutkan DataFrame berdasarkan Information Gain\nfeature_importance = feature_importance.sort_values(by='Information Gain', ascending=False)\n\n# Membuat diagram batang\nplt.figure(figsize=(10, 6))\nplt.barh(feature_importance['Feature'], feature_importance['Information Gain'])\nplt.xlabel('Information Gain')\nplt.ylabel('Feature')\nplt.title('Information Gain for Features')\nplt.show()\n\n\n\n\n\n# mengambil feature terbaik menggunakan kbest\nk = 12\nselector = SelectKBest(score_func=mutual_info_classif, k=k)\nX_new = selector.fit_transform(X, y)\nselected_feature_indices = selector.get_support(indices=True)\nselected_features = X.columns[selected_feature_indices]\nprint(f\"Fitur terbaik yang dipilih: {selected_features}\")\ndump(X_new, open('x.pkl', 'wb'))\ndump(y, open('y.pkl', 'wb'))\n\nFitur terbaik yang dipilih: Index(['Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA',\n       'GGT', 'PROT'],\n      dtype='object')"
  },
  {
    "objectID": "PSDtugasdata2.html#scaling-dan-mensplitmemisahkan-data-train-dan-data-test",
    "href": "PSDtugasdata2.html#scaling-dan-mensplitmemisahkan-data-train-dan-data-test",
    "title": "BUSSNIS UNDERSTANDING",
    "section": "Scaling dan Mensplit/memisahkan data train dan data test",
    "text": "Scaling dan Mensplit/memisahkan data train dan data test\n\nMensplit/memisahkan data train dan data test\nMembagi dataset menjadi data pelatihan (train data) dan data pengujian (test data) adalah langkah penting dalam pengembangan model machine learning. Tujuan utamanya adalah untuk mengevaluasi kinerja model pada data yang belum pernah dilihat sebelumnya, sehingga dapat memberikan perkiraan seberapa baik model tersebut dapat beradaptasi dengan data baru. Berikut adalah langkah-langkah umum untuk memisahkan data train dan test:\nSetelah pemisahan, Anda akan memiliki empat variabel:\n\nX_train: Fitur dari data pelatihan.\nX_test: Fitur dari data pengujian.\ny_train: Target dari data pelatihan.\ny_test: Target dari data pengujian.\n\nData pelatihan digunakan untuk melatih model, sementara data pengujian digunakan untuk menguji kinerja model.\n\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n\n\n\nBalencing data\nPada tahap ini akan menyeimbangkan data dengan menggunakan SMOTE, Bisa dilihat dibawah ini yang sebelumnya perbedaan yang sangat jauh, setelah dilakukan penyeimbangan data, data berubah menjadi seimbang.\n\nsmote = SMOTE(sampling_strategy='auto')\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n\nprint(pd.Series(y_train_resampled).value_counts())\n\n0    441\n1    441\nName: Category, dtype: int64\n\n\n\n\nScaling Menggunakan minmaxscaler\nMin-Max Scaling, yang sering dikenal juga dengan normalisasi data atau normalization (karena z-score juga sering disebut normalization, maka sering terjadi ambiguitas atau tertukar-tukar :D).\nMin-Max Scaling bekerja dengan scaling data/menyesuaikan data dalam rentang/range tertentu (range nilai minimum hingga nilai maksimum), dengan rentang yang biasa digunakan adalah 0 hingga 1. Berikut ini adalah uraian matematisnya:\n\\[ X_{\\text{normalized}} = \\frac{{X - X_{\\text{min}}}}{{X_{\\text{max}} - X_{\\text{min}}}} \\]\n\n\n\nX\n\n\n\n\n4\n\n\n7\n\n\n10\n\n\n5\n\n\n8\n\n\n\n\\[\\begin{align*}\n\\text{Min value:} & \\quad X_{\\text{min}} = 4 \\\\\n\\text{Max value:} & \\quad X_{\\text{max}} = 10 \\\\\n\\text{Original value / Data Yang ingin dinormalisasi:} & \\quad X = 7 \\\\\n\\text{Normalization formula:} & \\quad X_{\\text{normalized}} = \\frac{{X - X_{\\text{min}}}}{{X_{\\text{max}} - X_{\\text{min}}}} \\\\\n\\text{Calculation:} & \\quad X_{\\text{normalized}} = \\frac{{7 - 4}}{{10 - 4}} = \\frac{3}{6} = 0.5 \\\\\n\\end{align*}\\]\n\n# Scaling dan Mensplit/memisahkan data train dan data test, kemudian Menskalakan data dengan minmaxscaler\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train_resampled)\nX_test_scaled = scaler.transform(X_test)\ndump(X_test_scaled, open('scaled.pkl', 'wb'))"
  },
  {
    "objectID": "PSDtugasdata2.html#model-naive-bayes",
    "href": "PSDtugasdata2.html#model-naive-bayes",
    "title": "BUSSNIS UNDERSTANDING",
    "section": "MODEL NAIVE BAYES",
    "text": "MODEL NAIVE BAYES\nAlgoritma Naïve Bayes adalah teknik klasifikasi berdasarkan penerapan teorema Bayes dengan asumsi kuat bahwa semua prediktor independen satu sama lain. Klasifikasi Bayesian menyediakan cara menghitung probabilitas posterior P (A | B) dari P ( A ), P (B) dan P (B | A). Lihatlah persamaan di bawah ini: \\[ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} \\] Keterangan: - P (A | B) adalah probabilitas posterior kelas (A, target) yang diberikan prediktor (B, atribut). - P ( A ) adalah probabilitas kelas sebelumnya. - P (B | A) adalah kemungkinan yang merupakan probabilitas kelas yang diberikan prediktor. - P (B) adalah probabilitas prediktor sebelumnya.\nDalam contoh ini, kita akan membuat beberapa nilai imajiner: \\[ P(A) = 0.3 \\] \\[ P(B|A) = 0.6 \\] \\[ P(B) = 0.7 \\]\nRumus: \\[ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} \\]\nSubstitusi nilai: \\[ P(A|B) = \\frac{(0.6)(0.3)}{0.7} \\]\nHitung: \\[ P(A|B) = \\frac{0.18}{0.7} \\]\n\\[ P(A|B) \\approx 0.257 \\]\n\n#gaussianNB\nmodel = GaussianNB()\nmodel.fit(X_train_scaled, y_train_resampled)\ndump(model, open('gnb.pkl', 'wb'))\ny_pred = model.predict(X_test_scaled)\naccuracy = accuracy_score(y_test, y_pred)\naccuracy\n\n0.8861788617886179\n\n\n\ndf = pd.DataFrame({'Real Values':y_test, 'Predicted Values':y_pred})\ndf\n\n\n  \n    \n\n\n\n\n\n\nReal Values\nPredicted Values\n\n\n\n\n248\n0\n0\n\n\n365\n0\n0\n\n\n432\n0\n0\n\n\n610\n1\n1\n\n\n132\n0\n0\n\n\n...\n...\n...\n\n\n281\n0\n0\n\n\n291\n0\n0\n\n\n250\n0\n0\n\n\n11\n0\n0\n\n\n336\n0\n0\n\n\n\n\n\n123 rows × 2 columns"
  },
  {
    "objectID": "PSDtugasdata2.html#model-random-forest",
    "href": "PSDtugasdata2.html#model-random-forest",
    "title": "BUSSNIS UNDERSTANDING",
    "section": "MODEL RANDOM FOREST",
    "text": "MODEL RANDOM FOREST\nRandom Forest adalah salah satu algoritma machine learning yang digunakan untuk melakukan klasifikasi dan regresi pada data. Algoritma ini bekerja dengan cara menggabungkan beberapa pohon keputusan (decision tree) yang dibuat secara acak. Setiap pohon keputusan dalam Random Forest akan memilih fitur secara acak dan hanya menggunakan sebagian data untuk membuat keputusan. Kemudian, hasil dari setiap pohon keputusan akan digabungkan untuk menghasilkan prediksi akhir.\nFungsi utama dari Random Forest adalah untuk meningkatkan akurasi prediksi pada data yang kompleks dan besar. Algoritma ini juga dapat digunakan untuk mengatasi masalah overfitting pada model machine learning. Rumus atau formula yang digunakan dalam Random Forest adalah sebagai berikut:\n\nPembentukan pohon keputusan Untuk setiap pohon keputusan dalam Random Forest, rumus yang digunakan adalah: \\[ f(x) = sum_{i=1}^{m} w_i h_i(x) \\] Dimana: f(x) adalah output dari pohon keputusan, m adalah jumlah node dalam pohon keputusan, Wi adalah bobot dari setiap node dalam pohon keputusan, hi(x) adalah fungsi yang menghasilkan nilai 0 atau 1, tergantung pada apakah x memenuhi kondisi yang diberikan oleh node tersebut\nPembentukan Random Forest Untuk membentuk Random Forest, rumus yang digunakan adalah: \\[ F(x) = \\frac{1}{M} sum_{i=1}^{M} f_i(x) \\] Dimana: F(x) adalah output dari Random Forest, M adalah jumlah pohon keputusan dalam Random Forest, fi(x) adalah output dari pohon keputusan ke-i, Dengan menggunakan rumus di atas, Random Forest dapat menghasilkan prediksi yang akurat dan dapat digunakan untuk berbagai macam masalah dalam machine learning.\n\npada model ini akan menggunakan GridSearch untuk mencari best parameter dan score akurasi tertinggi.\n\n#GridsearchRandomForest\n\nrfc_model = RandomForestClassifier()\nrfc_params = {\n    \"n_estimators\": [100, 200, 300],\n    \"max_depth\": [5, 10, 20, None]\n}\n\ngrid_search_rfc = GridSearchCV(rfc_model, rfc_params, scoring='accuracy', cv=5)\ngrid_search_rfc.fit(X_train_scaled, y_train_resampled)\n\nbest_rfc_model = grid_search_rfc.best_estimator_\ny_pred_rfc = best_rfc_model.predict(X_test_scaled)\n\naccuracy_rfc = accuracy_score(y_test, y_pred_rfc)\n\nprint(\"Random Forest\")\nprint(f\"Best parameters: {grid_search_rfc.best_params_}\")\nprint(f\"Accuracy: {accuracy_rfc}\")\n\nRandom Forest\nBest parameters: {'max_depth': 10, 'n_estimators': 100}\nAccuracy: 0.975609756097561\n\n\n\nmodel2 = RandomForestClassifier(n_estimators=100, max_depth=10)\nmodel2.fit(X_train_scaled, y_train_resampled)\ny_pred3 = model2.predict(X_test_scaled)\naccuracy = accuracy_score(y_test, y_pred3)\naccuracy\n\n0.975609756097561\n\n\n\ndf = pd.DataFrame({'Real Values':y_test, 'Predicted Values':y_pred3})\ndf\n\n\n  \n    \n\n\n\n\n\n\nReal Values\nPredicted Values\n\n\n\n\n248\n0\n0\n\n\n365\n0\n0\n\n\n432\n0\n0\n\n\n610\n1\n1\n\n\n132\n0\n0\n\n\n...\n...\n...\n\n\n281\n0\n0\n\n\n291\n0\n0\n\n\n250\n0\n0\n\n\n11\n0\n0\n\n\n336\n0\n0\n\n\n\n\n\n123 rows × 2 columns"
  },
  {
    "objectID": "PSDtugasdata2.html#evaluasi-hasil-evaluate-result",
    "href": "PSDtugasdata2.html#evaluasi-hasil-evaluate-result",
    "title": "BUSSNIS UNDERSTANDING",
    "section": "Evaluasi Hasil (Evaluate result)",
    "text": "Evaluasi Hasil (Evaluate result)\nBerdasarkan hasil evaluasi diperoleh bahwa permodelan proyek ini sudah memenuhi tujuan penelitian seperti yang telah deijelaskan pada tahap pemahaman bisnis (Bussiness Understanding), yang dimana tujuan awalnya yaitu analisis dan klasifikasi pasien berdasarkan atribut yang diberikan, terutama untuk mengidentifikasi pasien yang adalah donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis."
  },
  {
    "objectID": "PSDtugasdata2.html#evaluasi-kinerja-model",
    "href": "PSDtugasdata2.html#evaluasi-kinerja-model",
    "title": "BUSSNIS UNDERSTANDING",
    "section": "Evaluasi Kinerja Model",
    "text": "Evaluasi Kinerja Model\nEvaluasi kinerja model Random Forest pada dataset tersebut memberikan informasi yang signifikan tentang seberapa baik model dapat memprediksi dan mengklasifikasikan data. Di bawah ini adalah penjelasan untuk beberapa komponen kunci dari evaluasi kinerja model:\n\nAkurasi (Accuracy):\n\n\nDeskripsi: Akurasi mengukur sejauh mana model dapat memprediksi dengan benar pada seluruh data pengujian.\nHasil: Akurasi model adalah 95.9%, yang mengindikasikan bahwa sekitar 95.9% dari seluruh pengujian diklasifikasikan dengan benar oleh model.\n\n\nMatriks Kebingungan (Confusion Matrix):\n\n\nDeskripsi: Matriks kebingungan memberikan gambaran tentang seberapa baik model dapat membedakan antara kelas positif dan kelas negatif.\nHasil: Matriks kebingungan menunjukkan bahwa model membuat 98 prediksi benar untuk kelas 0 (negatif) dan 20 prediksi benar untuk kelas 1 (positif), dengan 1 kesalahan prediksi untuk kelas 0 dan 4 kesalahan prediksi untuk kelas 1.\n\n\nLaporan Klasifikasi (Classification Report):\n\n\nDeskripsi: Laporan klasifikasi memberikan informasi rinci tentang kinerja model untuk setiap kelas, termasuk presisi, recall, dan F1-score.\nHasil: Untuk kelas 0 (negatif), model memiliki presisi sebesar 96%, recall sebesar 99%, dan F1-score sebesar 98%. Untuk kelas 1 (positif), presisi sebesar 95%, recall sebesar 83%, dan F1-score sebesar 89%.\n\n\nPrecision, Recall, dan F1-Score:\n\n\nPrecision: Menunjukkan sejauh mana prediksi positif yang dibuat oleh model adalah benar. Dalam konteks ini, presisi untuk kelas 0 adalah 96%, dan untuk kelas 1 adalah 95%.\nRecall (Sensitivitas): Menunjukkan sejauh mana model dapat menangkap atau mengidentifikasi semua instansi positif. Dalam konteks ini, recall untuk kelas 0 adalah 99%, dan untuk kelas 1 adalah 83%.\nF1-Score: Menggabungkan precision dan recall menjadi satu metrik yang menunjukkan seimbang antara keduanya. Dalam konteks ini, F1-score untuk kelas 0 adalah 98%, dan untuk kelas 1 adalah 89%.\n\n\naccuracy_rfc = accuracy_score(y_test, y_pred_rfc)\nconf_matrix_rfc = confusion_matrix(y_test, y_pred_rfc)\nclassification_rep_rfc = classification_report(y_test, y_pred_rfc)\n\nprint(\"Random Forest\")\nprint(f\"Best Model Accuracy: {accuracy_rfc:.3f}\")\nprint(\"Best Model Confusion Matrix:\")\nprint(conf_matrix_rfc)\nprint(\"Best Model Classification Report:\")\nprint(classification_rep_rfc)\n\nRandom Forest\nBest Model Accuracy: 0.976\nBest Model Confusion Matrix:\n[[99  0]\n [ 3 21]]\nBest Model Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.99        99\n           1       1.00      0.88      0.93        24\n\n    accuracy                           0.98       123\n   macro avg       0.99      0.94      0.96       123\nweighted avg       0.98      0.98      0.97       123"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Penulis: AKH.RAIHAN GIMNASTIAR RAKHMAN 210411100232\nTanggal: 12/3/2023"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KLASIFIKASI HEPATITIS C",
    "section": "",
    "text": "Link Implementasi Streamlit\nSelamat datang dalam perjalanan pengetahuan dan inovasi di dunia sains data yang mengarah pada pemahaman dan penanganan penyakit hepatitis C. Proyek ini menggabungkan kecanggihan teknologi sains data dengan urgensi penelitian medis untuk meningkatkan deteksi dini, diagnosis, dan pengelolaan penyakit yang memengaruhi jutaan orang di seluruh dunia.\nHepatitis C, yang disebabkan oleh virus hepatitis C (HCV), merupakan ancaman global terhadap kesehatan masyarakat. Dalam usaha untuk menghadapi tantangan ini, proyek sains data klasifikasi hepatitis C dibangun dengan tujuan utama: mengembangkan model klasifikasi yang dapat membedakan antara individu yang terinfeksi dan yang tidak terinfeksi, berdasarkan data klinis dan biomarker terkait.\nPendekatan ini mencakup penggalian data dari berbagai sumber, termasuk riwayat kesehatan, hasil tes laboratorium, dan faktor risiko lainnya. Melalui penerapan teknik-teknik analisis data canggih, seperti machine learning dan algoritma klasifikasi, proyek ini bertujuan untuk memberikan kontribusi signifikan dalam upaya mendeteksi hepatitis C lebih awal, mengarah pada penanganan yang lebih efektif.\nProyek ini tidak hanya mempertimbangkan aspek diagnostik, tetapi juga berfokus pada pemahaman lebih lanjut tentang faktor-faktor risiko yang mungkin berkontribusi pada penyebaran penyakit ini. Dengan memanfaatkan kekuatan sains data, kita berharap dapat mengidentifikasi pola-pola yang tersembunyi dalam data yang kompleks dan mendukung pencegahan lebih lanjut serta intervensi yang tepat.\nPentingnya proyek ini tidak hanya terletak pada kontribusinya terhadap perkembangan sains medis, tetapi juga pada potensi untuk meningkatkan kehidupan pasien dengan memungkinkan diagnosis dini, pengobatan yang lebih efektif, dan pengelolaan yang lebih baik. Semoga proyek ini menjadi tonggak penting dalam upaya global untuk mengatasi beban kesehatan masyarakat yang ditimbulkan oleh hepatitis C, membawa kita menuju masa depan yang lebih sehat dan berkelanjutan."
  }
]