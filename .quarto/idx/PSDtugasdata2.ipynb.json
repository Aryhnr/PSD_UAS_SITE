{"title":"**BUSSNIS UNDERSTANDING**","markdown":{"yaml":{"title":"**BUSSNIS UNDERSTANDING**"},"headingText":"**TUJUAN PROYEK**","containsRefs":false,"markdown":"\n\n\n\nData ini ditujukan untuk analisis dan klasifikasi pasien berdasarkan atribut yang diberikan, terutama untuk mengidentifikasi pasien yang adalah donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis.\n\nBerikut Untuk menentukan Klasifikasi pasien termasuk donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis :\n\n- Usia (dalam tahun)\n- Jenis Kelamin (f,m)\n- ALB\n- ALP\n- ALT\n- AST\n- BIL\n- CHE\n- CHOL\n- CREA\n- GGT\n- PROT\n\n\n\n# **DATA UNDERSTANDING**\n\n\n## **DESKRIPSI DATA**\nData ini dikumpulkan untuk tujuan menentukan klasifikasi pasien berdasarkan parameter kesehatan dan demografis. Setiap baris mewakili satu pasien, dengan informasi yang mencakup usia, jenis kelamin, dan sejumlah parameter kesehatan seperti ALB, ALP, ALT, AST, BIL, CHE, CHOL, CREA, GGT, dan PROT. Tujuan utama adalah mengklasifikasikan pasien ke dalam kategori diagnostik tertentu, seperti donor darah, tersangka donor darah, penderita Hepatitis, Fibrosis, atau Sirosis.\n\nData menyajikan keberagaman pasien dalam aspek usia dan jenis kelamin, memberikan konteks demografis. Selain itu, variabel-variabel kesehatan seperti kadar enzim, protein, dan zat lain dalam darah memberikan informasi tentang kondisi kesehatan dan fungsi organ pasien, terutama hati.\n\nAnalisis lebih lanjut dari data ini dapat melibatkan eksplorasi tren, identifikasi pola, dan pengembangan model prediktif untuk memahami hubungan antara parameter kesehatan dengan klasifikasi pasien. Informasi ini dapat bermanfaat untuk pengambilan keputusan klinis dan perencanaan perawatan yang lebih efektif berdasarkan karakteristik individu pasien.\n\n### **JUMLAH DATA**\nJumlah data mengacu pada total entitas atau elemen dalam suatu kumpulan atau struktur data. Ini bisa berupa jumlah baris dalam sebuah tabel, elemen dalam sebuah list, karakter dalam sebuah string, atau item dalam struktur data lainnya. Pemahaman jumlah data menjadi penting ketika kita ingin mengukur ukuran atau omvang dari setiap koleksi data dan memberikan gambaran tentang seberapa besar atau kecil kumpulan data tersebut. dari data yang dipakai pada proyek ini memiliki jumlah data 615 rows dengan 13 kolom, dari data tersebut dapat diketahui juga data di setiap category :\n\n- Blood Donor : 533 data\n- Suspect Blood Donor : 7 data\n- Hepatitis : 24 data\n- Fibrosis : 21 data\n- Cirrhosis : 30 data\n\n### **TYPE DATA**\nSemua atribut bertype data numerik kecuali atribut pada kolom \"Category\" dan \"Sex\"\n\n### **Mapping numeric values**\n\"Mapping numeric values\" merujuk pada proses mengaitkan atau menghubungkan suatu nilai numerik dengan nilai lainnya. Hal ini dapat dilakukan untuk berbagai tujuan, seperti mengubah rentang nilai, mengkategorikan data, atau menciptakan representasi yang lebih mudah dimengerti.\n\nBerikut adalah beberapa contoh penggunaan \"mapping numeric values\":\n\nNormalisasi Data:\nDalam analisis data, seringkali penting untuk mengubah nilai-nilai numerik sehingga mereka berada dalam rentang tertentu. Misalnya, jika Anda memiliki data yang tersebar di antara 0 dan 100, Anda mungkin ingin mengubahnya menjadi rentang 0 hingga 1.\n\nKategorisasi:\nAnda dapat menggolongkan nilai numerik ke dalam kategori tertentu. Misalnya, jika Anda memiliki data usia, Anda bisa membuat kategori seperti \"anak-anak,\" \"remaja,\" dan \"dewasa\" dengan mengaitkan rentang usia tertentu dengan setiap kategori.\n\nEncoding:\nDalam machine learning, khususnya pada pembelajaran mesin terhadap kategori atau label, seringkali diperlukan untuk mengonversi label kategori menjadi representasi numerik. Ini bisa dilakukan dengan membuat peta antara setiap kategori dan nilai numerik tertentu.\n\nVisualisasi Data:\nDalam visualisasi data, Anda mungkin ingin mengaitkan nilai-nilai numerik dengan warna atau ukuran untuk memperjelas pola atau perbedaan dalam data.\n\nTransformasi Fungsi:\nPemetaan nilai numerik dapat dilakukan melalui fungsi matematis atau transformasi. Sebagai contoh, mengkuadratkan atau mengakarkan nilai-nilai numerik untuk mengubah distribusi data.\n\nPada proses ini ada 2 kolom yang akan di mapping diantaranya ada \"Category\" pada kolom ini adalah kolom target yang aakan di mapping yang dimana value sebelumnya ada beberapa kategeri tapi pada dasarnya ada dua kategori yaitu donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis, jadi disini mapping menjadi dua yang dimana yang donor darah = 0 dan hepatitis C dengan tahap perkembangannya = 1.\nKemudian kolom \"Sex\" pada kolom ini yang akan di mapping m/male = 1 dan f/famale = 2\n\n\nMemeriksa kembali tipe data setelah transformasi\n\n## **EKSPLORASI DATA**\nEksplorasi Data (ED) adalah suatu proses analisis awal pada data untuk memahami dan meringkas karakteristik utama dari data tersebut. Tujuan dari eksplorasi data adalah mengidentifikasi pola, tren, anomali, dan informasi penting lainnya tanpa membuat asumsi sebelumnya. Eksplorasi data merupakan tahap kritis dalam analisis data dan dapat melibatkan berbagai metode, teknik, dan visualisasi data.\n\n### **Describe data**\nmengembalikan DataFrame baru yang berisi berbagai statistik untuk setiap kolom dalam DataFrame asli data. Statistik tersebut umumnya mencakup:\n\n- Count: Jumlah nilai non-null.\n- Mean: Nilai rata-rata atau rata-rata.\n- Std: Deviasi standar, ukuran sebaran data.\n- Min: Nilai minimum.\n- 25%: Kuartil pertama atau persentil ke-25.\n- 50%: Mediana atau persentil ke-50.\n- 75%: Kuartil ketiga atau persentil ke-75.\n- Max: Nilai maksimum.\n\nStatistik ini memberikan ringkasan cepat tentang distribusi setiap kolom numerik dalam DataFrame, membantu analis dan ilmuwan data untuk mendapatkan gambaran tentang kecenderungan sentral data, sebaran, dan bentuk keseluruhan. Perlu diingat bahwa statistik yang tepat dapat bervariasi berdasarkan versi pandas atau konfigurasi tertentu yang digunakan.\n\n### **Matrix correlation**\n\"Having a look at the correlation matrix\" adalah istilah yang merujuk pada kegiatan memeriksa atau menganalisis matriks korelasi. Matriks korelasi adalah suatu tabel yang menunjukkan seberapa erat hubungan antara dua atau lebih variabel. Ini memberikan informasi tentang arah dan kekuatan hubungan antar variabel tersebut.\n\nMatriks korelasi umumnya digunakan dalam statistika, analisis data, dan machine learning untuk memahami sejauh mana variabel-variabel saling terkait. Nilai korelasi berkisar antara -1 hingga 1, dengan interpretasi sebagai berikut:\n\n- 1: Korelasi sempurna (positif)\n- 0: Tidak ada korelasi\n- -1: Korelasi sempurna (negatif)\n\n### **Simple EDA**\nSimple EDA (Exploratory Data Analysis) adalah pendekatan awal dalam menganalisis dataset untuk mendapatkan pemahaman awal tentang karakteristik data dan mengidentifikasi pola atau informasi yang menarik. EDA merupakan langkah kritis dalam tahap persiapan data sebelum melakukan analisis yang lebih lanjut. Tujuannya adalah untuk membantu peneliti atau analis data memahami struktur dataset, mengidentifikasi anomali, dan merumuskan pertanyaan atau hipotesis yang lebih mendalam.\nmelakukan Exploratory Data Analysis (EDA) dengan membuat histogram untuk masing-masing variabel numerik dalam dataset, memperhatikan distribusi data dan melihat perbedaan distribusi antar kategori ('Category').\n\n\n### **DESKRIPSI SETIAP FEATURE DAN CARA PENGAMBILAN**\nPenjelasan dari setiap Featur data, Atribut 1 sampai dengan 4 mengacu pada data pasien:\n\n1. Kategori (diagnosis): Merupakan variabel target atau output yang ingin diprediksi atau dianalisis. Mewakili diagnosis pasien dan memiliki kategori nilai seperti '0=Donor Darah', '0s=tersangka Donor Darah', '1=Hepatitis', '2=Fibrosis', '3=Sirosis'. Ini adalah variabel kategorikal.\n\n2. Usia/Age (dalam tahun):\nMerupakan fitur yang mencatat usia pasien dalam tahun. Ini adalah variabel numerik kontinu dan dapat memberikan informasi tentang distribusi usia pasien dalam dataset.\n3. Jenis Kelamin (f,m):\nMerupakan kategorisasi jenis kelamin pasien, dengan nilai 'f' untuk perempuan dan 'm' untuk laki-laki. Ini adalah variabel kategorikal biner.\n\n4. ALB (Albumin): Albumin adalah protein yang diproduksi oleh hati dan merupakan salah satu komponen utama dalam serum darah. Pengukuran kadar albumin dapat memberikan informasi tentang fungsi hati.\n\n5. ALP (Alkaline Phosphatase): Alkaline phosphatase adalah enzim yang ditemukan di hati dan tulang. Peningkatan ALP dalam darah dapat menunjukkan masalah hati atau gangguan tulang.\n\n6. ALT (Alanine Aminotransferase): ALT adalah enzim hati yang terlibat dalam metabolisme asam amino. Peningkatan ALT dalam darah dapat menjadi tanda kerusakan hati, seperti pada hepatitis.\n\n7. AST (Aspartate Aminotransferase): AST juga merupakan enzim hati yang terlibat dalam metabolisme asam amino. Kadar AST yang tinggi dalam darah dapat mengindikasikan kerusakan hati atau gangguan lainnya.\n\n8. BIL (Bilirubin): Bilirubin adalah pigmen kuning yang dihasilkan ketika sel darah merah hancur. Kadar bilirubin yang tinggi dapat menjadi tanda masalah hati atau masalah dengan proses penguraian bilirubin dalam tubuh.\n\n9. CHE (Cholinesterase): Cholinesterase adalah enzim yang dapat memberikan informasi tentang fungsi hati. Penurunan kadar cholinesterase dalam darah dapat mengindikasikan kerusakan hati.\n\n10. CHOL (Cholesterol): Kolesterol adalah lemak yang penting untuk tubuh, tetapi kadar kolesterol yang tinggi dalam darah dapat meningkatkan risiko penyakit jantung.\n\n11. CREA (Creatinine): Creatinine adalah produk sisa dari metabolisme otot. Kadar kreatinin dalam darah dapat memberikan informasi tentang fungsi ginjal.\n\n12. GGT (Gamma-Glutamyl Transferase): GGT adalah enzim yang ditemukan di hati dan dapat meningkat pada berbagai gangguan hati, termasuk penyakit hati alkoholik.\n\n13. PROT (Protein): Kadar total protein dalam darah dapat memberikan informasi tentang status gizi dan kesehatan umum. Kadar protein yang rendah dalam darah dapat menjadi tanda masalah gizi atau penyakit hati.\n\nTeknik Pengambilan Sampel dengan menggunakan Darah (Serum atau Plasma):\n\n- Alat Pengambilan Sampel: Jarum suntik atau sarung tangan pengambil darah (vacutainer).\n- Teknik: Sampel darah biasanya diambil dari vena di lengan, seringkali dari vena di bagian dalam siku. Pada beberapa uji, dapat digunakan darah kapiler dari ujung jari.\n- Persiapan: Pasien biasanya diminta untuk berpuasa sebelum pengambilan darah pada uji tertentu.\n\n\n### **MISSING VALUE**\nMissing value (nilai yang hilang) dalam konteks data merujuk pada keadaan di mana tidak ada nilai atau informasi yang tersedia untuk suatu variabel atau kolom pada suatu pengamatan atau baris data tertentu. Missing value dapat muncul karena beberapa alasan, termasuk kesalahan pengukuran, kegagalan perangkat, atau karena karakteristik alami dari data.\n\nDalam analisis data, penanganan missing value menjadi penting karena dapat memengaruhi hasil analisis dan model yang dibangun. Beberapa strategi umum untuk menangani missing value termasuk:\n\n1. Menghapus Baris dengan Missing Value:\nMetode ini melibatkan penghapusan seluruh baris data yang mengandung missing value. Namun, ini dapat menyebabkan kehilangan informasi yang berharga jika banyak data hilang.\n\n2. Imputasi:\nImputasi melibatkan mengisi missing value dengan nilai yang diestimasi berdasarkan data yang ada. Ini bisa berupa mean, median, modus, atau nilai yang dihitung dari data lain.\n\n3. Model Berbasis Imputasi:\nMenggunakan model prediktif untuk memprediksi nilai yang hilang berdasarkan variabel lain. Contoh model berbasis imputasi termasuk regresi atau algoritma machine learning.\n\n4. Peningkatan Pengumpulan Data:\nMelibatkan upaya untuk meningkatkan pengumpulan data agar lebih lengkap dan mengurangi jumlah missing value di masa depan.\n\n5. Menandai Missing Value:\nMenggunakan penanda khusus (seperti NaN - Not a Number) untuk mengidentifikasi missing value dan mengizinkan model atau analisis data untuk mengatasi keberadaan nilai yang hilang secara eksplisit.\n\nPada test diatas detemukan missing value pada table :\n- ALB : 1\n- ALP : 18\n- ALT : 1\n- CHOL : 10\n- PROT : 1\n\nMengisi Missing value dengan Rata-Rata\n\nPengecekan Kembali Missng value\n\nMissing value sudah terisi\n\n### **Balencing Data**\nKumpulan data yang tidak seimbang menimbulkan tantangan umum bagi praktisi pembelajaran mesin dalam masalah klasifikasi biner. Skenario ini sering muncul dalam aplikasi bisnis praktis seperti deteksi penipuan, pemfilteran spam , penemuan penyakit langka, dan deteksi kesalahan perangkat keras. Untuk mengatasi masalah ini, salah satu teknik yang populer adalah Synthetic Minority Oversampling Technique (SMOTE). SMOTE dirancang khusus untuk mengatasi kumpulan data yang tidak seimbang dengan menghasilkan sampel sintetis untuk kelas minoritas.\n\nDapat dilihat hasil dari percobaan diatas menghasilkan data yang sangat tidak seimbang 540 berbanding dengang 75, tentu hasil ini memiliki perbadaan yang sangat jauh, oleh karena itu perlu adanya balencing data.\n\n### **Outliers**\nOutliers, atau nilai-nilai ekstrem, adalah titik data yang signifikan atau ekstrim yang berbeda secara signifikan dari mayoritas data dalam sebuah kumpulan data. Outliers dapat muncul dalam berbagai bentuk dan dapat mempengaruhi analisis statistik karena mereka dapat menyebabkan kesalahan dalam estimasi parameter dan menarik hasil analisis ke arah yang tidak akurat.\n\n# **PREPROCESSING DATA**\nHal-hal yang dilakukan pada preprosed\n- Memisahkan feature dan target\n- seleksi feature\n- Mencari fitur data terbaik menggunakan information gain dan kbest\n- Scaling, Balencing data dan Mensplit/memisahkan data train dan data test\n\n## **Memisahkan Feature dan Target**\nPada tahap ini akan melakukan pemisahan terhadap sebuah colom, yang nantinya akan dipisah menjadi mana kolom sebagai feature dan mana kolom yang sebagai target, berikut table yang akan dipisah :\n- Feature : Age, Sex, ALB, ALP, ALT, AST, BIL, CHE, CHOL, CREA, GGT, PROT\n- Targer  : Category\n\n## **Seleksi Feature**\nInformation Gain adalah ukuran yang digunakan dalam konteks pohon keputusan (decision tree) untuk menilai seberapa baik suatu fitur dapat memisahkan data menjadi kelas yang berbeda. Information Gain dihitung dengan mengukur seberapa banyak informasi yang diberikan oleh suatu fitur terhadap pemisahan kelas dalam suatu dataset. Semakin tinggi Information Gain, semakin baik fitur tersebut dalam memprediksi kelas.\n\nInformation Gain biasanya digunakan dalam algoritma pembelajaran mesin yang berbasis pohon, seperti ID3 (Iterative Dichotomiser 3) atau C4.5. Pada setiap tahap pembangunan pohon keputusan, algoritma mencari fitur dengan Information Gain tertinggi untuk memilih sebagai node pemisah berikutnya.\n\nk-Best:\nk-Best merujuk pada teknik pemilihan fitur di mana kita memilih k fitur terbaik berdasarkan suatu metrik atau skor tertentu. Metode ini membantu untuk mengurangi dimensi dataset dengan memilih subset fitur yang paling informatif atau yang paling berkontribusi dalam memprediksi variabel target.\n\nTeknik pemilihan fitur k-Best umumnya menggunakan skor atau metrik seperti chi-square, f-regression, mutual information, dll., untuk menilai pentingnya setiap fitur. Kemudian, k fitur terbaik dipilih berdasarkan skor tersebut.\n\n## **Scaling dan Mensplit/memisahkan data train dan data test**\n\n\n\n\n\n\n### **Mensplit/memisahkan data train dan data test**\nMembagi dataset menjadi data pelatihan (train data) dan data pengujian (test data) adalah langkah penting dalam pengembangan model machine learning. Tujuan utamanya adalah untuk mengevaluasi kinerja model pada data yang belum pernah dilihat sebelumnya, sehingga dapat memberikan perkiraan seberapa baik model tersebut dapat beradaptasi dengan data baru. Berikut adalah langkah-langkah umum untuk memisahkan data train dan test:\n\nSetelah pemisahan, Anda akan memiliki empat variabel:\n\n- X_train: Fitur dari data pelatihan.\n- X_test: Fitur dari data pengujian.\n- y_train: Target dari data pelatihan.\n- y_test: Target dari data pengujian.\n\nData pelatihan digunakan untuk melatih model, sementara data pengujian digunakan untuk menguji kinerja model.\n\n### **Balencing data**\nPada tahap ini akan menyeimbangkan data dengan menggunakan SMOTE, Bisa dilihat dibawah ini yang sebelumnya perbedaan yang sangat jauh, setelah dilakukan penyeimbangan data, data berubah menjadi seimbang.\n\n### **Scaling Menggunakan minmaxscaler**\n\nMin-Max Scaling, yang sering dikenal juga dengan normalisasi data atau normalization (karena z-score juga sering disebut normalization, maka sering terjadi ambiguitas atau tertukar-tukar :D).\n\nMin-Max Scaling bekerja dengan scaling data/menyesuaikan data dalam rentang/range tertentu (range nilai minimum hingga nilai maksimum), dengan rentang yang biasa digunakan adalah 0 hingga 1. Berikut ini adalah uraian matematisnya:\n\n$$ X_{\\text{normalized}} = \\frac{{X - X_{\\text{min}}}}{{X_{\\text{max}} - X_{\\text{min}}}} $$\n\n| X |\n| --- |\n| 4 |\n| 7 |\n| 10 |\n| 5 |\n| 8 |\n\n\\begin{align*}\n\\text{Min value:} & \\quad X_{\\text{min}} = 4 \\\\\n\\text{Max value:} & \\quad X_{\\text{max}} = 10 \\\\\n\\text{Original value / Data Yang ingin dinormalisasi:} & \\quad X = 7 \\\\\n\\text{Normalization formula:} & \\quad X_{\\text{normalized}} = \\frac{{X - X_{\\text{min}}}}{{X_{\\text{max}} - X_{\\text{min}}}} \\\\\n\\text{Calculation:} & \\quad X_{\\text{normalized}} = \\frac{{7 - 4}}{{10 - 4}} = \\frac{3}{6} = 0.5 \\\\\n\\end{align*}\n\n# **IMPLEMENTASI**\nHal-hal yang dilakukan pada Implementasi\n\n1.   Setelah data di split, data kemudian dilatih menggunakan model\n2.   menghitung score akurasi setiap model(mencari model dengan akurasi terbaik)\n\n## **MODEL NAIVE BAYES**\nAlgoritma Naïve Bayes adalah teknik klasifikasi berdasarkan penerapan teorema Bayes dengan asumsi kuat bahwa semua prediktor independen satu sama lain. Klasifikasi Bayesian menyediakan cara menghitung probabilitas posterior P (A | B) dari P ( A ), P (B) dan P (B | A). Lihatlah persamaan di bawah ini:\n$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\nKeterangan:\n- P (A | B) adalah probabilitas posterior kelas (A, target) yang diberikan prediktor (B, atribut).\n- P ( A ) adalah probabilitas kelas sebelumnya.\n- P (B | A) adalah kemungkinan yang merupakan probabilitas kelas yang diberikan prediktor.\n- P (B) adalah probabilitas prediktor sebelumnya.\n\n\nDalam contoh ini, kita akan membuat beberapa nilai imajiner:\n$$ P(A) = 0.3 $$\n$$ P(B|A) = 0.6 $$\n$$ P(B) = 0.7 $$\n\nRumus:\n$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n\nSubstitusi nilai:\n$$ P(A|B) = \\frac{(0.6)(0.3)}{0.7} $$\n\nHitung:\n$$ P(A|B) = \\frac{0.18}{0.7} $$\n\n$$ P(A|B) \\approx 0.257 $$\n\n\n\n## **MODEL RANDOM FOREST**\nRandom Forest adalah salah satu algoritma machine learning yang digunakan untuk melakukan klasifikasi dan regresi pada data. Algoritma ini bekerja dengan cara menggabungkan beberapa pohon keputusan (decision tree) yang dibuat secara acak. Setiap pohon keputusan dalam Random Forest akan memilih fitur secara acak dan hanya menggunakan sebagian data untuk membuat keputusan. Kemudian, hasil dari setiap pohon keputusan akan digabungkan untuk menghasilkan prediksi akhir.\n\nFungsi utama dari Random Forest adalah untuk meningkatkan akurasi prediksi pada data yang kompleks dan besar. Algoritma ini juga dapat digunakan untuk mengatasi masalah overfitting pada model machine learning.\nRumus atau formula yang digunakan dalam Random Forest adalah sebagai berikut:\n\n1. Pembentukan pohon keputusan\nUntuk setiap pohon keputusan dalam Random Forest, rumus yang digunakan adalah:\n$$ f(x) = sum_{i=1}^{m} w_i h_i(x) $$\nDimana:\nf(x) adalah output dari pohon keputusan, m adalah jumlah node dalam pohon keputusan, Wi adalah bobot dari setiap node dalam pohon keputusan, hi(x) adalah fungsi yang menghasilkan nilai 0 atau 1, tergantung pada apakah x memenuhi kondisi yang diberikan oleh node tersebut\n2. Pembentukan Random Forest\nUntuk membentuk Random Forest, rumus yang digunakan adalah:\n$$ F(x) = \\frac{1}{M} sum_{i=1}^{M} f_i(x) $$\nDimana:\nF(x) adalah output dari Random Forest, M adalah jumlah pohon keputusan dalam Random Forest, fi(x) adalah output dari pohon keputusan ke-i, Dengan menggunakan rumus di atas, Random Forest dapat menghasilkan prediksi yang akurat dan dapat digunakan untuk berbagai macam masalah dalam machine learning.\n\npada model ini akan menggunakan GridSearch untuk mencari best parameter dan score akurasi tertinggi.\n\n# **EVALUASI**\n## Evaluasi Hasil (Evaluate result)\nBerdasarkan hasil evaluasi diperoleh bahwa permodelan proyek ini sudah memenuhi tujuan penelitian seperti yang telah deijelaskan pada tahap pemahaman bisnis (Bussiness Understanding), yang dimana tujuan awalnya yaitu analisis dan klasifikasi pasien berdasarkan atribut yang diberikan, terutama untuk mengidentifikasi pasien yang adalah donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis.\n\n\n## Evaluasi Kinerja Model\nEvaluasi kinerja model Random Forest pada dataset tersebut memberikan informasi yang signifikan tentang seberapa baik model dapat memprediksi dan mengklasifikasikan data. Di bawah ini adalah penjelasan untuk beberapa komponen kunci dari evaluasi kinerja model:\n\n1. Akurasi (Accuracy):\n  - Deskripsi: Akurasi mengukur sejauh mana model dapat memprediksi dengan benar pada seluruh data pengujian.\n  - Hasil: Akurasi model adalah 95.9%, yang mengindikasikan bahwa sekitar 95.9% dari seluruh pengujian diklasifikasikan dengan benar oleh model.\n\n2. Matriks Kebingungan (Confusion Matrix):\n  - Deskripsi: Matriks kebingungan memberikan gambaran tentang seberapa baik model dapat membedakan antara kelas positif dan kelas negatif.\n  - Hasil: Matriks kebingungan menunjukkan bahwa model membuat 98 prediksi benar untuk kelas 0 (negatif) dan 20 prediksi benar untuk kelas 1 (positif), dengan 1 kesalahan prediksi untuk kelas 0 dan 4 kesalahan prediksi untuk kelas 1.\n\n3. Laporan Klasifikasi (Classification Report):\n  - Deskripsi: Laporan klasifikasi memberikan informasi rinci tentang kinerja model untuk setiap kelas, termasuk presisi, recall, dan F1-score.\n  - Hasil: Untuk kelas 0 (negatif), model memiliki presisi sebesar 96%, recall sebesar 99%, dan F1-score sebesar 98%. Untuk kelas 1 (positif), presisi sebesar 95%, recall sebesar 83%, dan F1-score sebesar 89%.\n\n4. Precision, Recall, dan F1-Score:\n  - Precision: Menunjukkan sejauh mana prediksi positif yang dibuat oleh model adalah benar. Dalam konteks ini, presisi untuk kelas 0 adalah 96%, dan untuk kelas 1 adalah 95%.\n  - Recall (Sensitivitas): Menunjukkan sejauh mana model dapat menangkap atau mengidentifikasi semua instansi positif. Dalam konteks ini, recall untuk kelas 0 adalah 99%, dan untuk kelas 1 adalah 83%.\n  - F1-Score: Menggabungkan precision dan recall menjadi satu metrik yang menunjukkan seimbang antara keduanya. Dalam konteks ini, F1-score untuk kelas 0 adalah 98%, dan untuk kelas 1 adalah 89%.\n","srcMarkdownNoYaml":"\n\n\n\n## **TUJUAN PROYEK**\nData ini ditujukan untuk analisis dan klasifikasi pasien berdasarkan atribut yang diberikan, terutama untuk mengidentifikasi pasien yang adalah donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis.\n\nBerikut Untuk menentukan Klasifikasi pasien termasuk donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis :\n\n- Usia (dalam tahun)\n- Jenis Kelamin (f,m)\n- ALB\n- ALP\n- ALT\n- AST\n- BIL\n- CHE\n- CHOL\n- CREA\n- GGT\n- PROT\n\n\n\n# **DATA UNDERSTANDING**\n\n\n## **DESKRIPSI DATA**\nData ini dikumpulkan untuk tujuan menentukan klasifikasi pasien berdasarkan parameter kesehatan dan demografis. Setiap baris mewakili satu pasien, dengan informasi yang mencakup usia, jenis kelamin, dan sejumlah parameter kesehatan seperti ALB, ALP, ALT, AST, BIL, CHE, CHOL, CREA, GGT, dan PROT. Tujuan utama adalah mengklasifikasikan pasien ke dalam kategori diagnostik tertentu, seperti donor darah, tersangka donor darah, penderita Hepatitis, Fibrosis, atau Sirosis.\n\nData menyajikan keberagaman pasien dalam aspek usia dan jenis kelamin, memberikan konteks demografis. Selain itu, variabel-variabel kesehatan seperti kadar enzim, protein, dan zat lain dalam darah memberikan informasi tentang kondisi kesehatan dan fungsi organ pasien, terutama hati.\n\nAnalisis lebih lanjut dari data ini dapat melibatkan eksplorasi tren, identifikasi pola, dan pengembangan model prediktif untuk memahami hubungan antara parameter kesehatan dengan klasifikasi pasien. Informasi ini dapat bermanfaat untuk pengambilan keputusan klinis dan perencanaan perawatan yang lebih efektif berdasarkan karakteristik individu pasien.\n\n### **JUMLAH DATA**\nJumlah data mengacu pada total entitas atau elemen dalam suatu kumpulan atau struktur data. Ini bisa berupa jumlah baris dalam sebuah tabel, elemen dalam sebuah list, karakter dalam sebuah string, atau item dalam struktur data lainnya. Pemahaman jumlah data menjadi penting ketika kita ingin mengukur ukuran atau omvang dari setiap koleksi data dan memberikan gambaran tentang seberapa besar atau kecil kumpulan data tersebut. dari data yang dipakai pada proyek ini memiliki jumlah data 615 rows dengan 13 kolom, dari data tersebut dapat diketahui juga data di setiap category :\n\n- Blood Donor : 533 data\n- Suspect Blood Donor : 7 data\n- Hepatitis : 24 data\n- Fibrosis : 21 data\n- Cirrhosis : 30 data\n\n### **TYPE DATA**\nSemua atribut bertype data numerik kecuali atribut pada kolom \"Category\" dan \"Sex\"\n\n### **Mapping numeric values**\n\"Mapping numeric values\" merujuk pada proses mengaitkan atau menghubungkan suatu nilai numerik dengan nilai lainnya. Hal ini dapat dilakukan untuk berbagai tujuan, seperti mengubah rentang nilai, mengkategorikan data, atau menciptakan representasi yang lebih mudah dimengerti.\n\nBerikut adalah beberapa contoh penggunaan \"mapping numeric values\":\n\nNormalisasi Data:\nDalam analisis data, seringkali penting untuk mengubah nilai-nilai numerik sehingga mereka berada dalam rentang tertentu. Misalnya, jika Anda memiliki data yang tersebar di antara 0 dan 100, Anda mungkin ingin mengubahnya menjadi rentang 0 hingga 1.\n\nKategorisasi:\nAnda dapat menggolongkan nilai numerik ke dalam kategori tertentu. Misalnya, jika Anda memiliki data usia, Anda bisa membuat kategori seperti \"anak-anak,\" \"remaja,\" dan \"dewasa\" dengan mengaitkan rentang usia tertentu dengan setiap kategori.\n\nEncoding:\nDalam machine learning, khususnya pada pembelajaran mesin terhadap kategori atau label, seringkali diperlukan untuk mengonversi label kategori menjadi representasi numerik. Ini bisa dilakukan dengan membuat peta antara setiap kategori dan nilai numerik tertentu.\n\nVisualisasi Data:\nDalam visualisasi data, Anda mungkin ingin mengaitkan nilai-nilai numerik dengan warna atau ukuran untuk memperjelas pola atau perbedaan dalam data.\n\nTransformasi Fungsi:\nPemetaan nilai numerik dapat dilakukan melalui fungsi matematis atau transformasi. Sebagai contoh, mengkuadratkan atau mengakarkan nilai-nilai numerik untuk mengubah distribusi data.\n\nPada proses ini ada 2 kolom yang akan di mapping diantaranya ada \"Category\" pada kolom ini adalah kolom target yang aakan di mapping yang dimana value sebelumnya ada beberapa kategeri tapi pada dasarnya ada dua kategori yaitu donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis, jadi disini mapping menjadi dua yang dimana yang donor darah = 0 dan hepatitis C dengan tahap perkembangannya = 1.\nKemudian kolom \"Sex\" pada kolom ini yang akan di mapping m/male = 1 dan f/famale = 2\n\n\nMemeriksa kembali tipe data setelah transformasi\n\n## **EKSPLORASI DATA**\nEksplorasi Data (ED) adalah suatu proses analisis awal pada data untuk memahami dan meringkas karakteristik utama dari data tersebut. Tujuan dari eksplorasi data adalah mengidentifikasi pola, tren, anomali, dan informasi penting lainnya tanpa membuat asumsi sebelumnya. Eksplorasi data merupakan tahap kritis dalam analisis data dan dapat melibatkan berbagai metode, teknik, dan visualisasi data.\n\n### **Describe data**\nmengembalikan DataFrame baru yang berisi berbagai statistik untuk setiap kolom dalam DataFrame asli data. Statistik tersebut umumnya mencakup:\n\n- Count: Jumlah nilai non-null.\n- Mean: Nilai rata-rata atau rata-rata.\n- Std: Deviasi standar, ukuran sebaran data.\n- Min: Nilai minimum.\n- 25%: Kuartil pertama atau persentil ke-25.\n- 50%: Mediana atau persentil ke-50.\n- 75%: Kuartil ketiga atau persentil ke-75.\n- Max: Nilai maksimum.\n\nStatistik ini memberikan ringkasan cepat tentang distribusi setiap kolom numerik dalam DataFrame, membantu analis dan ilmuwan data untuk mendapatkan gambaran tentang kecenderungan sentral data, sebaran, dan bentuk keseluruhan. Perlu diingat bahwa statistik yang tepat dapat bervariasi berdasarkan versi pandas atau konfigurasi tertentu yang digunakan.\n\n### **Matrix correlation**\n\"Having a look at the correlation matrix\" adalah istilah yang merujuk pada kegiatan memeriksa atau menganalisis matriks korelasi. Matriks korelasi adalah suatu tabel yang menunjukkan seberapa erat hubungan antara dua atau lebih variabel. Ini memberikan informasi tentang arah dan kekuatan hubungan antar variabel tersebut.\n\nMatriks korelasi umumnya digunakan dalam statistika, analisis data, dan machine learning untuk memahami sejauh mana variabel-variabel saling terkait. Nilai korelasi berkisar antara -1 hingga 1, dengan interpretasi sebagai berikut:\n\n- 1: Korelasi sempurna (positif)\n- 0: Tidak ada korelasi\n- -1: Korelasi sempurna (negatif)\n\n### **Simple EDA**\nSimple EDA (Exploratory Data Analysis) adalah pendekatan awal dalam menganalisis dataset untuk mendapatkan pemahaman awal tentang karakteristik data dan mengidentifikasi pola atau informasi yang menarik. EDA merupakan langkah kritis dalam tahap persiapan data sebelum melakukan analisis yang lebih lanjut. Tujuannya adalah untuk membantu peneliti atau analis data memahami struktur dataset, mengidentifikasi anomali, dan merumuskan pertanyaan atau hipotesis yang lebih mendalam.\nmelakukan Exploratory Data Analysis (EDA) dengan membuat histogram untuk masing-masing variabel numerik dalam dataset, memperhatikan distribusi data dan melihat perbedaan distribusi antar kategori ('Category').\n\n\n### **DESKRIPSI SETIAP FEATURE DAN CARA PENGAMBILAN**\nPenjelasan dari setiap Featur data, Atribut 1 sampai dengan 4 mengacu pada data pasien:\n\n1. Kategori (diagnosis): Merupakan variabel target atau output yang ingin diprediksi atau dianalisis. Mewakili diagnosis pasien dan memiliki kategori nilai seperti '0=Donor Darah', '0s=tersangka Donor Darah', '1=Hepatitis', '2=Fibrosis', '3=Sirosis'. Ini adalah variabel kategorikal.\n\n2. Usia/Age (dalam tahun):\nMerupakan fitur yang mencatat usia pasien dalam tahun. Ini adalah variabel numerik kontinu dan dapat memberikan informasi tentang distribusi usia pasien dalam dataset.\n3. Jenis Kelamin (f,m):\nMerupakan kategorisasi jenis kelamin pasien, dengan nilai 'f' untuk perempuan dan 'm' untuk laki-laki. Ini adalah variabel kategorikal biner.\n\n4. ALB (Albumin): Albumin adalah protein yang diproduksi oleh hati dan merupakan salah satu komponen utama dalam serum darah. Pengukuran kadar albumin dapat memberikan informasi tentang fungsi hati.\n\n5. ALP (Alkaline Phosphatase): Alkaline phosphatase adalah enzim yang ditemukan di hati dan tulang. Peningkatan ALP dalam darah dapat menunjukkan masalah hati atau gangguan tulang.\n\n6. ALT (Alanine Aminotransferase): ALT adalah enzim hati yang terlibat dalam metabolisme asam amino. Peningkatan ALT dalam darah dapat menjadi tanda kerusakan hati, seperti pada hepatitis.\n\n7. AST (Aspartate Aminotransferase): AST juga merupakan enzim hati yang terlibat dalam metabolisme asam amino. Kadar AST yang tinggi dalam darah dapat mengindikasikan kerusakan hati atau gangguan lainnya.\n\n8. BIL (Bilirubin): Bilirubin adalah pigmen kuning yang dihasilkan ketika sel darah merah hancur. Kadar bilirubin yang tinggi dapat menjadi tanda masalah hati atau masalah dengan proses penguraian bilirubin dalam tubuh.\n\n9. CHE (Cholinesterase): Cholinesterase adalah enzim yang dapat memberikan informasi tentang fungsi hati. Penurunan kadar cholinesterase dalam darah dapat mengindikasikan kerusakan hati.\n\n10. CHOL (Cholesterol): Kolesterol adalah lemak yang penting untuk tubuh, tetapi kadar kolesterol yang tinggi dalam darah dapat meningkatkan risiko penyakit jantung.\n\n11. CREA (Creatinine): Creatinine adalah produk sisa dari metabolisme otot. Kadar kreatinin dalam darah dapat memberikan informasi tentang fungsi ginjal.\n\n12. GGT (Gamma-Glutamyl Transferase): GGT adalah enzim yang ditemukan di hati dan dapat meningkat pada berbagai gangguan hati, termasuk penyakit hati alkoholik.\n\n13. PROT (Protein): Kadar total protein dalam darah dapat memberikan informasi tentang status gizi dan kesehatan umum. Kadar protein yang rendah dalam darah dapat menjadi tanda masalah gizi atau penyakit hati.\n\nTeknik Pengambilan Sampel dengan menggunakan Darah (Serum atau Plasma):\n\n- Alat Pengambilan Sampel: Jarum suntik atau sarung tangan pengambil darah (vacutainer).\n- Teknik: Sampel darah biasanya diambil dari vena di lengan, seringkali dari vena di bagian dalam siku. Pada beberapa uji, dapat digunakan darah kapiler dari ujung jari.\n- Persiapan: Pasien biasanya diminta untuk berpuasa sebelum pengambilan darah pada uji tertentu.\n\n\n### **MISSING VALUE**\nMissing value (nilai yang hilang) dalam konteks data merujuk pada keadaan di mana tidak ada nilai atau informasi yang tersedia untuk suatu variabel atau kolom pada suatu pengamatan atau baris data tertentu. Missing value dapat muncul karena beberapa alasan, termasuk kesalahan pengukuran, kegagalan perangkat, atau karena karakteristik alami dari data.\n\nDalam analisis data, penanganan missing value menjadi penting karena dapat memengaruhi hasil analisis dan model yang dibangun. Beberapa strategi umum untuk menangani missing value termasuk:\n\n1. Menghapus Baris dengan Missing Value:\nMetode ini melibatkan penghapusan seluruh baris data yang mengandung missing value. Namun, ini dapat menyebabkan kehilangan informasi yang berharga jika banyak data hilang.\n\n2. Imputasi:\nImputasi melibatkan mengisi missing value dengan nilai yang diestimasi berdasarkan data yang ada. Ini bisa berupa mean, median, modus, atau nilai yang dihitung dari data lain.\n\n3. Model Berbasis Imputasi:\nMenggunakan model prediktif untuk memprediksi nilai yang hilang berdasarkan variabel lain. Contoh model berbasis imputasi termasuk regresi atau algoritma machine learning.\n\n4. Peningkatan Pengumpulan Data:\nMelibatkan upaya untuk meningkatkan pengumpulan data agar lebih lengkap dan mengurangi jumlah missing value di masa depan.\n\n5. Menandai Missing Value:\nMenggunakan penanda khusus (seperti NaN - Not a Number) untuk mengidentifikasi missing value dan mengizinkan model atau analisis data untuk mengatasi keberadaan nilai yang hilang secara eksplisit.\n\nPada test diatas detemukan missing value pada table :\n- ALB : 1\n- ALP : 18\n- ALT : 1\n- CHOL : 10\n- PROT : 1\n\nMengisi Missing value dengan Rata-Rata\n\nPengecekan Kembali Missng value\n\nMissing value sudah terisi\n\n### **Balencing Data**\nKumpulan data yang tidak seimbang menimbulkan tantangan umum bagi praktisi pembelajaran mesin dalam masalah klasifikasi biner. Skenario ini sering muncul dalam aplikasi bisnis praktis seperti deteksi penipuan, pemfilteran spam , penemuan penyakit langka, dan deteksi kesalahan perangkat keras. Untuk mengatasi masalah ini, salah satu teknik yang populer adalah Synthetic Minority Oversampling Technique (SMOTE). SMOTE dirancang khusus untuk mengatasi kumpulan data yang tidak seimbang dengan menghasilkan sampel sintetis untuk kelas minoritas.\n\nDapat dilihat hasil dari percobaan diatas menghasilkan data yang sangat tidak seimbang 540 berbanding dengang 75, tentu hasil ini memiliki perbadaan yang sangat jauh, oleh karena itu perlu adanya balencing data.\n\n### **Outliers**\nOutliers, atau nilai-nilai ekstrem, adalah titik data yang signifikan atau ekstrim yang berbeda secara signifikan dari mayoritas data dalam sebuah kumpulan data. Outliers dapat muncul dalam berbagai bentuk dan dapat mempengaruhi analisis statistik karena mereka dapat menyebabkan kesalahan dalam estimasi parameter dan menarik hasil analisis ke arah yang tidak akurat.\n\n# **PREPROCESSING DATA**\nHal-hal yang dilakukan pada preprosed\n- Memisahkan feature dan target\n- seleksi feature\n- Mencari fitur data terbaik menggunakan information gain dan kbest\n- Scaling, Balencing data dan Mensplit/memisahkan data train dan data test\n\n## **Memisahkan Feature dan Target**\nPada tahap ini akan melakukan pemisahan terhadap sebuah colom, yang nantinya akan dipisah menjadi mana kolom sebagai feature dan mana kolom yang sebagai target, berikut table yang akan dipisah :\n- Feature : Age, Sex, ALB, ALP, ALT, AST, BIL, CHE, CHOL, CREA, GGT, PROT\n- Targer  : Category\n\n## **Seleksi Feature**\nInformation Gain adalah ukuran yang digunakan dalam konteks pohon keputusan (decision tree) untuk menilai seberapa baik suatu fitur dapat memisahkan data menjadi kelas yang berbeda. Information Gain dihitung dengan mengukur seberapa banyak informasi yang diberikan oleh suatu fitur terhadap pemisahan kelas dalam suatu dataset. Semakin tinggi Information Gain, semakin baik fitur tersebut dalam memprediksi kelas.\n\nInformation Gain biasanya digunakan dalam algoritma pembelajaran mesin yang berbasis pohon, seperti ID3 (Iterative Dichotomiser 3) atau C4.5. Pada setiap tahap pembangunan pohon keputusan, algoritma mencari fitur dengan Information Gain tertinggi untuk memilih sebagai node pemisah berikutnya.\n\nk-Best:\nk-Best merujuk pada teknik pemilihan fitur di mana kita memilih k fitur terbaik berdasarkan suatu metrik atau skor tertentu. Metode ini membantu untuk mengurangi dimensi dataset dengan memilih subset fitur yang paling informatif atau yang paling berkontribusi dalam memprediksi variabel target.\n\nTeknik pemilihan fitur k-Best umumnya menggunakan skor atau metrik seperti chi-square, f-regression, mutual information, dll., untuk menilai pentingnya setiap fitur. Kemudian, k fitur terbaik dipilih berdasarkan skor tersebut.\n\n## **Scaling dan Mensplit/memisahkan data train dan data test**\n\n\n\n\n\n\n### **Mensplit/memisahkan data train dan data test**\nMembagi dataset menjadi data pelatihan (train data) dan data pengujian (test data) adalah langkah penting dalam pengembangan model machine learning. Tujuan utamanya adalah untuk mengevaluasi kinerja model pada data yang belum pernah dilihat sebelumnya, sehingga dapat memberikan perkiraan seberapa baik model tersebut dapat beradaptasi dengan data baru. Berikut adalah langkah-langkah umum untuk memisahkan data train dan test:\n\nSetelah pemisahan, Anda akan memiliki empat variabel:\n\n- X_train: Fitur dari data pelatihan.\n- X_test: Fitur dari data pengujian.\n- y_train: Target dari data pelatihan.\n- y_test: Target dari data pengujian.\n\nData pelatihan digunakan untuk melatih model, sementara data pengujian digunakan untuk menguji kinerja model.\n\n### **Balencing data**\nPada tahap ini akan menyeimbangkan data dengan menggunakan SMOTE, Bisa dilihat dibawah ini yang sebelumnya perbedaan yang sangat jauh, setelah dilakukan penyeimbangan data, data berubah menjadi seimbang.\n\n### **Scaling Menggunakan minmaxscaler**\n\nMin-Max Scaling, yang sering dikenal juga dengan normalisasi data atau normalization (karena z-score juga sering disebut normalization, maka sering terjadi ambiguitas atau tertukar-tukar :D).\n\nMin-Max Scaling bekerja dengan scaling data/menyesuaikan data dalam rentang/range tertentu (range nilai minimum hingga nilai maksimum), dengan rentang yang biasa digunakan adalah 0 hingga 1. Berikut ini adalah uraian matematisnya:\n\n$$ X_{\\text{normalized}} = \\frac{{X - X_{\\text{min}}}}{{X_{\\text{max}} - X_{\\text{min}}}} $$\n\n| X |\n| --- |\n| 4 |\n| 7 |\n| 10 |\n| 5 |\n| 8 |\n\n\\begin{align*}\n\\text{Min value:} & \\quad X_{\\text{min}} = 4 \\\\\n\\text{Max value:} & \\quad X_{\\text{max}} = 10 \\\\\n\\text{Original value / Data Yang ingin dinormalisasi:} & \\quad X = 7 \\\\\n\\text{Normalization formula:} & \\quad X_{\\text{normalized}} = \\frac{{X - X_{\\text{min}}}}{{X_{\\text{max}} - X_{\\text{min}}}} \\\\\n\\text{Calculation:} & \\quad X_{\\text{normalized}} = \\frac{{7 - 4}}{{10 - 4}} = \\frac{3}{6} = 0.5 \\\\\n\\end{align*}\n\n# **IMPLEMENTASI**\nHal-hal yang dilakukan pada Implementasi\n\n1.   Setelah data di split, data kemudian dilatih menggunakan model\n2.   menghitung score akurasi setiap model(mencari model dengan akurasi terbaik)\n\n## **MODEL NAIVE BAYES**\nAlgoritma Naïve Bayes adalah teknik klasifikasi berdasarkan penerapan teorema Bayes dengan asumsi kuat bahwa semua prediktor independen satu sama lain. Klasifikasi Bayesian menyediakan cara menghitung probabilitas posterior P (A | B) dari P ( A ), P (B) dan P (B | A). Lihatlah persamaan di bawah ini:\n$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\nKeterangan:\n- P (A | B) adalah probabilitas posterior kelas (A, target) yang diberikan prediktor (B, atribut).\n- P ( A ) adalah probabilitas kelas sebelumnya.\n- P (B | A) adalah kemungkinan yang merupakan probabilitas kelas yang diberikan prediktor.\n- P (B) adalah probabilitas prediktor sebelumnya.\n\n\nDalam contoh ini, kita akan membuat beberapa nilai imajiner:\n$$ P(A) = 0.3 $$\n$$ P(B|A) = 0.6 $$\n$$ P(B) = 0.7 $$\n\nRumus:\n$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n\nSubstitusi nilai:\n$$ P(A|B) = \\frac{(0.6)(0.3)}{0.7} $$\n\nHitung:\n$$ P(A|B) = \\frac{0.18}{0.7} $$\n\n$$ P(A|B) \\approx 0.257 $$\n\n\n\n## **MODEL RANDOM FOREST**\nRandom Forest adalah salah satu algoritma machine learning yang digunakan untuk melakukan klasifikasi dan regresi pada data. Algoritma ini bekerja dengan cara menggabungkan beberapa pohon keputusan (decision tree) yang dibuat secara acak. Setiap pohon keputusan dalam Random Forest akan memilih fitur secara acak dan hanya menggunakan sebagian data untuk membuat keputusan. Kemudian, hasil dari setiap pohon keputusan akan digabungkan untuk menghasilkan prediksi akhir.\n\nFungsi utama dari Random Forest adalah untuk meningkatkan akurasi prediksi pada data yang kompleks dan besar. Algoritma ini juga dapat digunakan untuk mengatasi masalah overfitting pada model machine learning.\nRumus atau formula yang digunakan dalam Random Forest adalah sebagai berikut:\n\n1. Pembentukan pohon keputusan\nUntuk setiap pohon keputusan dalam Random Forest, rumus yang digunakan adalah:\n$$ f(x) = sum_{i=1}^{m} w_i h_i(x) $$\nDimana:\nf(x) adalah output dari pohon keputusan, m adalah jumlah node dalam pohon keputusan, Wi adalah bobot dari setiap node dalam pohon keputusan, hi(x) adalah fungsi yang menghasilkan nilai 0 atau 1, tergantung pada apakah x memenuhi kondisi yang diberikan oleh node tersebut\n2. Pembentukan Random Forest\nUntuk membentuk Random Forest, rumus yang digunakan adalah:\n$$ F(x) = \\frac{1}{M} sum_{i=1}^{M} f_i(x) $$\nDimana:\nF(x) adalah output dari Random Forest, M adalah jumlah pohon keputusan dalam Random Forest, fi(x) adalah output dari pohon keputusan ke-i, Dengan menggunakan rumus di atas, Random Forest dapat menghasilkan prediksi yang akurat dan dapat digunakan untuk berbagai macam masalah dalam machine learning.\n\npada model ini akan menggunakan GridSearch untuk mencari best parameter dan score akurasi tertinggi.\n\n# **EVALUASI**\n## Evaluasi Hasil (Evaluate result)\nBerdasarkan hasil evaluasi diperoleh bahwa permodelan proyek ini sudah memenuhi tujuan penelitian seperti yang telah deijelaskan pada tahap pemahaman bisnis (Bussiness Understanding), yang dimana tujuan awalnya yaitu analisis dan klasifikasi pasien berdasarkan atribut yang diberikan, terutama untuk mengidentifikasi pasien yang adalah donor darah dan mereka yang menderita Hepatitis C atau tahap-tahap perkembangan Hepatitis C, seperti Fibrosis dan Sirosis.\n\n\n## Evaluasi Kinerja Model\nEvaluasi kinerja model Random Forest pada dataset tersebut memberikan informasi yang signifikan tentang seberapa baik model dapat memprediksi dan mengklasifikasikan data. Di bawah ini adalah penjelasan untuk beberapa komponen kunci dari evaluasi kinerja model:\n\n1. Akurasi (Accuracy):\n  - Deskripsi: Akurasi mengukur sejauh mana model dapat memprediksi dengan benar pada seluruh data pengujian.\n  - Hasil: Akurasi model adalah 95.9%, yang mengindikasikan bahwa sekitar 95.9% dari seluruh pengujian diklasifikasikan dengan benar oleh model.\n\n2. Matriks Kebingungan (Confusion Matrix):\n  - Deskripsi: Matriks kebingungan memberikan gambaran tentang seberapa baik model dapat membedakan antara kelas positif dan kelas negatif.\n  - Hasil: Matriks kebingungan menunjukkan bahwa model membuat 98 prediksi benar untuk kelas 0 (negatif) dan 20 prediksi benar untuk kelas 1 (positif), dengan 1 kesalahan prediksi untuk kelas 0 dan 4 kesalahan prediksi untuk kelas 1.\n\n3. Laporan Klasifikasi (Classification Report):\n  - Deskripsi: Laporan klasifikasi memberikan informasi rinci tentang kinerja model untuk setiap kelas, termasuk presisi, recall, dan F1-score.\n  - Hasil: Untuk kelas 0 (negatif), model memiliki presisi sebesar 96%, recall sebesar 99%, dan F1-score sebesar 98%. Untuk kelas 1 (positif), presisi sebesar 95%, recall sebesar 83%, dan F1-score sebesar 89%.\n\n4. Precision, Recall, dan F1-Score:\n  - Precision: Menunjukkan sejauh mana prediksi positif yang dibuat oleh model adalah benar. Dalam konteks ini, presisi untuk kelas 0 adalah 96%, dan untuk kelas 1 adalah 95%.\n  - Recall (Sensitivitas): Menunjukkan sejauh mana model dapat menangkap atau mengidentifikasi semua instansi positif. Dalam konteks ini, recall untuk kelas 0 adalah 99%, dan untuk kelas 1 adalah 83%.\n  - F1-Score: Menggabungkan precision dan recall menjadi satu metrik yang menunjukkan seimbang antara keduanya. Dalam konteks ini, F1-score untuk kelas 0 adalah 98%, dan untuk kelas 1 adalah 89%.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"PSDtugasdata2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"cosmo","title":"**BUSSNIS UNDERSTANDING**"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}